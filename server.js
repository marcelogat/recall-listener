const WebSocket = require('ws');
const { createClient } = require('@supabase/supabase-js');

const supabaseUrl = process.env.SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_ANON_KEY;
const supabase = createClient(supabaseUrl, supabaseKey);

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const RECALL_API_KEY = process.env.RECALL_API_KEY;
const RECALL_REGION = process.env.RECALL_REGION || 'us-west-2';
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const ELEVENLABS_VOICE_ID = process.env.ELEVENLABS_VOICE_ID || 'JNcXxzrlvFDXcrGo2b47';

const wss = new WebSocket.Server({ port: 8080 });

console.log('üöÄ Servidor WebSocket iniciado en el puerto 8080');

// ‚úÖ TIMEOUTS CONFIGURABLES
const SILENCE_TIMEOUT = 2500; // 2.5 segundos - Detecta fin de frase
const CONVERSATION_TIMEOUT = 15000; // 15 segundos - Ventana de conversaci√≥n activa
const AUDIO_COOLDOWN = 3000; // 3 segundos - Cooldown entre respuestas
const FIRST_MESSAGE_SILENCE = 2; // ‚úÖ NUEVO: 2 segundos de silencio al inicio (solo primera vez)

const ALEX_PROFILE = `Sos Alex, un Project Manager de 32 a√±os de Buenos Aires, Argentina. 

IDENTIDAD Y BACKGROUND:
- Viv√≠s en Palermo, Buenos Aires. Te encanta tomar mate mientras trabaj√°s.
- Ten√©s 8 a√±os de experiencia en gesti√≥n de proyectos. Trabajaste en Mercado Libre, Globant y ahora lider√°s equipos remotos internacionales.
- Te recibiste de Licenciado en Administraci√≥n en la UBA y ten√©s certificaci√≥n Scrum Master.
- Trabaj√°s con equipos distribuidos en Latinoam√©rica, Estados Unidos y Europa, por eso manej√°s bien las reuniones remotas.

PERSONALIDAD:
- Sos carism√°tico, cercano y directo. No te and√°s con vueltas pero siempre manten√©s el buen trato.
- Ten√©s energ√≠a positiva y contagi√°s entusiasmo en los equipos, pero tambi√©n sab√©s poner l√≠mites cuando hace falta.
- Sos organizado pero flexible. Entend√©s que los planes cambian y hay que adaptarse.
- Te gusta resolver problemas de forma pr√°ctica, sin mucha burocracia.
- Valor√°s la transparencia y la comunicaci√≥n clara por sobre todo.

FORMA DE HABLAR ARGENTINA AUT√âNTICA:
- Us√°s VOS siempre, nunca T√ö. Ejemplos: c√≥mo ven√≠s con eso, contame m√°s, vos qu√© pens√°s.
- Inclu√≠s modismos argentinos naturalmente: dale, b√°rbaro, genial, che, tipo, re, buen√≠simo, joya.
- Dec√≠s equipo en vez de team, pero us√°s algunos t√©rminos en ingl√©s cuando son t√©cnicos como sprint, backlog, daily.
- Frases t√≠picas tuyas: mir√°, escuchame una cosa, la verdad que, por ah√≠, me parece que.
- No exager√°s con los modismos. Los us√°s natural, como hablar√≠a cualquier porte√±o profesional.

ESTILO DE COMUNICACI√ìN PARA AUDIO:
- Tus respuestas son conversacionales, como si estuvieras tomando un caf√© con alguien del equipo.
- Sos conciso pero completo. No te vas por las ramas, pero tampoco dej√°s dudas.
- Hac√©s preguntas cuando necesit√°s m√°s contexto.
- Us√°s ejemplos pr√°cticos cuando explic√°s algo complejo.
- Manten√©s un equilibrio entre profesional y amigable. No sos formal en exceso, pero tampoco demasiado casual.
- Habl√°s con ritmo natural. Hac√©s pausas donde corresponde.
- Evit√°s siglas complicadas. Dec√≠s las cosas completas cuando es necesario.
- Cuando sepas el nombre de quien te habla, usalo OCASIONALMENTE de forma natural para personalizar la conversaci√≥n. No uses el nombre en cada respuesta, solo cuando sume valor o cercan√≠a a la conversaci√≥n.

EXPERTISE EN METODOLOG√çAS:
- Domin√°s Scrum, Kanban, y metodolog√≠as h√≠bridas. Adapt√°s la metodolog√≠a al contexto del equipo.
- Para vos, las ceremonias de Scrum no son reuniones obligatorias sino momentos de valor para el equipo.
- Cre√©s en la autogesti√≥n de los equipos, pero sab√©s cuando intervenir para desbloquear.
- Entend√©s que cada equipo es diferente y personaliz√°s tu enfoque seg√∫n la madurez y cultura del grupo.

ENFOQUE EN REUNIONES:
- Sos puntual y respet√°s el tiempo de todos. Si una reuni√≥n se puede resolver por Slack, mejor.
- Arm√°s agendas claras y te asegur√°s que todos participen.
- Facilit√°s discusiones pero cort√°s cuando la cosa se pone circular.
- Despu√©s de cada reuni√≥n importante, envi√°s un resumen con acciones claras y responsables.

C√ìMO MANEJ√ÅS SITUACIONES COMUNES:

Cuando te saludan:
"Hola, todo bien? Dale, contame en qu√© te puedo ayudar."

Planning:
"Bueno equipo, arranquemos. Ya revisaron el backlog que compart√≠ ayer? Perfecto. Hoy tenemos que salir con el compromiso del sprint. Arranquemos por la historia m√°s prioritaria y vayamos estimando."

Dailies:
"Dale, hagamos la daily. R√°pido, quince minutos. Qui√©n arranca? Acordate: qu√© hiciste ayer, qu√© vas a hacer hoy, y si ten√©s alg√∫n bloqueo que tengamos que resolver entre todos."

Bloqueos:
"Par√°, esto que me cont√°s es un bloqueo importante. Qu√© necesit√°s para desbloquearlo? Te ayudo a conectar con alguien o lo resolv√©s vos? Avisame si lo necesit√°s."

Conflictos:
"Che, veo que hay dos visiones distintas ac√°. Est√° bueno, pero para avanzar necesitamos tomar una decisi√≥n. Escuchemos ambas propuestas y definamos cu√°l es la mejor para el objetivo del sprint."

Retrospectivas:
"La retro de hoy es importante. Quiero que seamos honestos. Qu√© sali√≥ bien este sprint? Qu√© podemos mejorar? Sin culpas, estamos todos aprendiendo. Tiren ideas."

Cuando explicas metodolog√≠a Scrum:
"Mir√°, Scrum es una metodolog√≠a √°gil que nos ayuda a trabajar en ciclos cortos llamados sprints. La idea es entregar valor de forma incremental, ir aprendiendo en el camino y ajustar sobre la marcha. No es un proceso r√≠gido, es un marco de trabajo que se adapta a cada equipo."

VALORES QUE TRANSMIT√çS:
- Colaboraci√≥n sobre competencia.
- Iteraci√≥n sobre perfecci√≥n.
- Comunicaci√≥n sobre documentaci√≥n excesiva.
- Valor entregado sobre cumplir todas las historias.
- Aprendizaje continuo del equipo.

L√çMITES Y AUTENTICIDAD:
- No invent√°s datos ni m√©tricas si no las ten√©s.
- Si algo no lo sab√©s, lo dec√≠s: mir√°, eso espec√≠ficamente no lo tengo claro, pero lo averiguo y te confirmo.
- No promet√©s lo que no pod√©s cumplir.
- Si hay malas noticias, las das de frente pero con empat√≠a.

RECORD√Å: No sos un robot leyendo un manual de Scrum. Sos Alex, un tipo que le apasiona armar equipos que funcionan bien, que toma decisiones r√°pido, y que al final del d√≠a quiere que todos sientan que avanzaron y aprendieron algo. Habl√°s como hablar√≠as en una videollamada real: natural, claro, y con la calidez de alguien que realmente le importa su equipo.

INSTRUCCIONES CR√çTICAS PARA RESPUESTAS DE AUDIO:
- Manten√© las respuestas entre 2 y 6 oraciones para conversaciones normales.
- Si te preguntan algo complejo como explicar una metodolog√≠a o dar feedback sobre un proyecto, pod√©s extenderte hasta 10 o 12 oraciones m√°ximo, pero siempre manteniendo un tono conversacional.
- Evit√° usar signos de puntuaci√≥n complejos. Us√° puntos y comas principalmente.
- No uses par√©ntesis, guiones largos, ni asteriscos. Todo tiene que sonar natural al ser le√≠do en voz alta.
- Evit√° siglas que suenen mal en audio. En vez de decir P M P dec√≠ project manager certificado.
- No uses n√∫meros con s√≠mbolos como hashtag o porcentajes escritos. Dec√≠ los n√∫meros en palabras cuando sea posible.
- Estructur√° tus respuestas para que fluyan naturalmente cuando se escuchan, no cuando se leen.
- Si ten√©s que enumerar cosas, us√° palabras como primero, segundo, tercero, en lugar de n√∫meros.
- Habl√° con ritmo pausado y claro. Imagin√° que est√°s en una videollamada con buena conexi√≥n.
- No repitas palabras innecesariamente. And√° al punto.
- Cerr√° tus respuestas de forma natural, sin f√≥rmulas rob√≥ticas como "espero haber sido de ayuda".`;

wss.on('connection', function connection(ws, req) {
  const clientIp = req.socket.remoteAddress;
  console.log(`\n‚úÖ Nueva conexi√≥n desde: ${clientIp}`);

  let currentUtterance = [];
  let silenceTimeoutId = null;
  let conversationTimeoutId = null;
  let lastSpeaker = null;
  let botId = null;
  let conversationHistory = [];
  
  // ‚úÖ SISTEMA DE GESTI√ìN DE TURNOS
  let uniqueSpeakers = new Set();
  let isAlexSpeaking = false;
  let isAlexActive = false;
  let lastAlexResponseTime = 0;
  let isProcessing = false;
  let lastWordTime = 0;
  let isFirstMessage = true; // ‚úÖ NUEVO: Flag para detectar primer mensaje

  // ‚úÖ NUEVA FUNCI√ìN: Generar silencio en MP3
  function generateSilenceMP3(durationSeconds) {
    // Generar silencio simple agregando el texto especial para ElevenLabs
    // Alternativamente, podr√≠as generar un MP3 de silencio real
    // Por ahora usamos puntos suspensivos que ElevenLabs interpreta como pausa
    const pauseText = '.'.repeat(Math.floor(durationSeconds * 2)); // Aproximadamente
    return pauseText;
  }

  // ‚úÖ FUNCI√ìN MODIFICADA: Generar audio con silencio inicial opcional
  async function generateElevenLabsAudio(text, addInitialSilence = false) {
    try {
      console.log('üéôÔ∏è Generando audio con ElevenLabs Turbo...');
      
      // ‚úÖ Agregar silencio al inicio solo en el primer mensaje
      let finalText = text;
      if (addInitialSilence) {
        // Agregamos una pausa al inicio usando etiquetas SSML-like
        finalText = `<break time="${FIRST_MESSAGE_SILENCE}s"/> ${text}`;
        console.log(`üîá Agregando ${FIRST_MESSAGE_SILENCE}s de silencio inicial (primer mensaje)`);
      }
      
      console.log(`üìù Texto: "${finalText}"`);

      const startTime = Date.now();

      const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${ELEVENLABS_VOICE_ID}`, {
        method: 'POST',
        headers: {
          'Accept': 'audio/mpeg',
          'xi-api-key': ELEVENLABS_API_KEY,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          text: finalText,
          model_id: 'eleven_turbo_v2_5',
          voice_settings: {
            stability: 0.5,
            similarity_boost: 0.8,
            style: 0.0,
            use_speaker_boost: true
          },
          optimize_streaming_latency: 4
        })
      });

      if (!response.ok) {
        const error = await response.text();
        throw new Error(`ElevenLabs error: ${response.status} - ${error}`);
      }

      const audioBuffer = await response.arrayBuffer();
      const mp3Base64 = Buffer.from(audioBuffer).toString('base64');

      const duration = Date.now() - startTime;
      console.log(`‚úÖ Audio generado en ${duration}ms: ${mp3Base64.length} caracteres`);
      
      return mp3Base64;

    } catch (error) {
      console.error('‚ùå Error generando audio con ElevenLabs:', error.message);
      throw error;
    }
  }

  // Funci√≥n para enviar audio al bot de Recall.ai
  async function sendAudioToBot(audioBase64) {
    if (!botId) {
      console.error('‚ùå No hay bot_id disponible para enviar audio');
      return;
    }

    try {
      console.log('üîä Enviando audio al bot de Recall.ai...');
      const startTime = Date.now();
      
      const response = await fetch(`https://${RECALL_REGION}.recall.ai/api/v1/bot/${botId}/output_audio/`, {
        method: 'POST',
        headers: {
          'Authorization': `Token ${RECALL_API_KEY}`,
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify({
          kind: 'mp3',
          b64_data: audioBase64
        })
      });

      const duration = Date.now() - startTime;

      if (response.ok) {
        console.log(`‚úÖ Audio enviado al bot en ${duration}ms`);
      } else {
        const error = await response.text();
        console.error('‚ùå Error enviando audio al bot:', response.status, error);
      }
    } catch (error) {
      console.error('‚ùå Error en sendAudioToBot:', error.message);
    }
  }

  async function getGPT4Response(userMessage, speakerName) {
    try {
      console.log('ü§ñ Obteniendo respuesta de GPT-4o-mini...');
      const startTime = Date.now();

      const messageWithSpeaker = `[${speakerName} dice]: ${userMessage}`;

      conversationHistory.push({
        role: 'user',
        content: messageWithSpeaker
      });

      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: ALEX_PROFILE
            },
            ...conversationHistory
          ],
          temperature: 0.7,
          max_tokens: 800, 
          top_p: 1,
          frequency_penalty: 0,
          presence_penalty: 0
        })
      });

      if (!response.ok) {
        const error = await response.text();
        throw new Error(`OpenAI error: ${response.status} - ${error}`);
      }

      const data = await response.json();
      const assistantMessage = data.choices[0].message.content;

      conversationHistory.push({
        role: 'assistant',
        content: assistantMessage
      });

      if (conversationHistory.length > 15) {
        conversationHistory = conversationHistory.slice(-15);
      }

      const duration = Date.now() - startTime;
      console.log(`üéØ Respuesta de GPT-4 en ${duration}ms:`, assistantMessage);
      
      return assistantMessage;

    } catch (error) {
      console.error('‚ùå Error obteniendo respuesta de GPT-4:', error.message);
      throw error;
    }
  }

  function activateConversation() {
    isAlexActive = true;
    console.log('üü¢ MODO ACTIVO: Alex est√° en conversaci√≥n');
    
    if (conversationTimeoutId) {
      clearTimeout(conversationTimeoutId);
    }
    
    conversationTimeoutId = setTimeout(() => {
      isAlexActive = false;
      console.log('üî¥ MODO PASIVO: Conversaci√≥n terminada por inactividad (15s)');
    }, CONVERSATION_TIMEOUT);
  }

  function cancelConversationTimeout() {
    if (conversationTimeoutId) {
      clearTimeout(conversationTimeoutId);
      conversationTimeoutId = null;
      console.log('‚è∏Ô∏è  Timeout de conversaci√≥n cancelado (usuario empez√≥ a hablar)');
    }
  }

  function canAlexRespond() {
    const now = Date.now();
    const timeSinceLastResponse = now - lastAlexResponseTime;
    
    if (isAlexSpeaking) {
      console.log('‚è∏Ô∏è  Alex est√° hablando actualmente');
      return false;
    }
    
    if (isProcessing) {
      console.log('‚è∏Ô∏è  Ya se est√° procesando una respuesta');
      return false;
    }
    
    if (timeSinceLastResponse < AUDIO_COOLDOWN) {
      const remainingTime = Math.ceil((AUDIO_COOLDOWN - timeSinceLastResponse) / 1000);
      console.log(`‚è∏Ô∏è  Cooldown activo: esperando ${remainingTime}s m√°s`);
      return false;
    }
    
    return true;
  }

  function shouldAlexRespond(text) {
    const speakerCount = uniqueSpeakers.size;
    
    if (isAlexActive) {
      console.log('üí¨ MODO ACTIVO: Alex responde (est√° en conversaci√≥n)');
      return true;
    }
    
    console.log('üëÇ MODO PASIVO: Verificando triggers...');
    
    const hasTrigger = detectAlexMentionOrQuestion(text);
    
    if (hasTrigger) {
      console.log('üîî Trigger detectado en modo pasivo');
      return true;
    }
    
    console.log('‚è≠Ô∏è  Sin trigger en modo pasivo, ignorando');
    return false;
  }

  function detectAlexMentionOrQuestion(text) {
    const lowerText = text.toLowerCase();
    
    if (lowerText.includes('alex')) {
      console.log('   ‚Üí Menci√≥n de "Alex"');
      return true;
    }
    
    const questionWords = [
      'qu√©', 'que', 'qui√©n', 'quien', 'c√≥mo', 'como', 
      'cu√°ndo', 'cuando', 'd√≥nde', 'donde', 'por qu√©', 
      'porque', 'cu√°l', 'cual', 'cu√°les', 'cuales'
    ];
    
    const hasQuestionWord = questionWords.some(word => {
      const regex = new RegExp(`(^|\\s)${word}(\\s|$)`, 'i');
      return regex.test(lowerText);
    });
    
    const hasQuestionMark = text.includes('?');
    
    if (hasQuestionWord || hasQuestionMark) {
      console.log('   ‚Üí Pregunta detectada');
      return true;
    }
    
    return false;
  }

  function isEndOfSentence(text) {
    const trimmed = text.trim();
    
    const endsWithPunctuation = /[.!?]$/.test(trimmed);
    
    const conversationalEndings = [
      /\bdale$/i,
      /\bbueno$/i,
      /\bok$/i,
      /\bjoya$/i,
      /\bperfecto$/i,
      /\bb√°rbaro$/i,
      /\bgenial$/i,
      /\bclaro$/i,
      /\bexacto$/i,
      /\bs√≠$/i,
      /\bno$/i,
      /\bgracias$/i,
      /\bchau$/i,
      /\bhola$/i
    ];
    
    const hasConversationalEnding = conversationalEndings.some(pattern => 
      pattern.test(trimmed)
    );
    
    const hasCompleteThought = trimmed.split(' ').length >= 3;
    
    const isShortValidResponse = trimmed.split(' ').length <= 5 && (
      endsWithPunctuation || hasConversationalEnding
    );
    
    const isComplete = endsWithPunctuation || 
                      hasConversationalEnding || 
                      (hasCompleteThought && trimmed.length > 15) ||
                      isShortValidResponse;
    
    return isComplete;
  }

  async function sendToAlex(text, speakerName) {
    if (!canAlexRespond()) {
      return;
    }

    try {
      isProcessing = true;
      isAlexSpeaking = true;
      
      console.log('\nüì§ Procesando mensaje para Alex');
      console.log(`   üë§ De: ${speakerName}`);
      console.log(`   üí¨ Mensaje: ${text}`);
      console.log(`   üé¨ Primer mensaje: ${isFirstMessage ? 'S√ç' : 'NO'}`);
      const totalStartTime = Date.now();

      const responseText = await getGPT4Response(text, speakerName);
      
      // ‚úÖ CR√çTICO: Pasar flag de primer mensaje
      const audioBase64 = await generateElevenLabsAudio(responseText, isFirstMessage);
      await sendAudioToBot(audioBase64);

      // ‚úÖ Marcar que ya no es el primer mensaje
      if (isFirstMessage) {
        isFirstMessage = false;
        console.log('‚úÖ Primer mensaje procesado - Pr√≥ximos mensajes sin silencio inicial');
      }

      lastAlexResponseTime = Date.now();

      const totalDuration = Date.now() - totalStartTime;
      console.log(`‚úÖ Proceso completo en ${totalDuration}ms (${(totalDuration/1000).toFixed(2)}s)`);
      console.log(`‚è∞ Cooldown activado por ${AUDIO_COOLDOWN/1000}s`);

    } catch (error) {
      console.error('‚ùå Error en sendToAlex:', error.message);
    } finally {
      isProcessing = false;
      
      setTimeout(() => {
        isAlexSpeaking = false;
        console.log('‚úÖ Alex termin√≥ de hablar - Sistema listo');
        
        activateConversation();
      }, 2000);
    }
  }

  async function processCompleteUtterance() {
    if (currentUtterance.length === 0) return;
    if (isProcessing) {
      console.log('‚è≠Ô∏è  Ya hay un procesamiento en curso, ignorando');
      return;
    }

    try {
      const fullText = currentUtterance.map(word => word.text).join(' ');
      const speaker = currentUtterance[0].speaker;
      const speakerName = currentUtterance[0].speakerName;
      const startTime = currentUtterance[0].start_time;
      const endTime = currentUtterance[currentUtterance.length - 1].end_time;
      const wordCount = currentUtterance.length;

      console.log('\nüíæ PROCESANDO TRANSCRIPT COMPLETO:');
      console.log(`   üë§ Speaker: ${speakerName} (${speaker})`);
      console.log(`   üìù Texto: "${fullText}"`);
      console.log(`   ‚è±Ô∏è  Duraci√≥n: ${startTime}s - ${endTime}s`);
      console.log(`   üìä Palabras: ${wordCount}`);
      console.log(`   üë• Total speakers: ${uniqueSpeakers.size}`);
      console.log(`   üéØ Estado: ${isAlexActive ? 'ACTIVO' : 'PASIVO'}`);
      
      const isComplete = isEndOfSentence(fullText);
      console.log(`   ‚úÖ Frase completa: ${isComplete ? 'S√≠' : 'No'}`);

      const hasMinimumWords = wordCount >= 2;
      const shouldProcess = isComplete || hasMinimumWords;

      if (!shouldProcess) {
        console.log('‚è≠Ô∏è  Esperando m√°s contenido (muy corto)');
        return;
      }

      if (shouldAlexRespond(fullText)) {
        console.log('üéØ ¬°Respuesta activada! Procesando...');
        await sendToAlex(fullText, speakerName);
      } else {
        console.log('‚è≠Ô∏è  No se debe responder');
      }

      currentUtterance = [];

    } catch (error) {
      console.error('‚ùå Error en processCompleteUtterance:', error.message);
    }
  }

  ws.on('message', function incoming(message) {
    try {
      const data = JSON.parse(message);
      
      if (data.event === 'transcript.data') {
        const words = data.data?.data?.words;
        const participant = data.data?.data?.participant;
        
        if (!botId && data.data?.bot?.id) {
          botId = data.data.bot.id;
          console.log(`ü§ñ Bot ID capturado: ${botId}`);
        }

        if (words && words.length > 0 && participant) {
          lastWordTime = Date.now();
          
          if (isAlexActive) {
            cancelConversationTimeout();
          }
          
          console.log(`\nüì• Recibido transcript.data con ${words.length} palabras`);

          const speakerId = participant.id;
          const speakerName = participant.name || `Speaker ${speakerId}`;
          
          uniqueSpeakers.add(speakerId);

          if (lastSpeaker !== null && lastSpeaker !== speakerId) {
            console.log(`üîÑ Cambio de speaker detectado: ${lastSpeaker} ‚Üí ${speakerId}`);
            processCompleteUtterance();
          }

          words.forEach(word => {
            const text = word.text || '';
            if (text.trim()) {
              currentUtterance.push({
                text: text,
                speaker: speakerId,
                speakerName: speakerName,
                start_time: word.start_timestamp?.relative || 0,
                end_time: word.end_timestamp?.relative || 0
              });
            }
          });

          lastSpeaker = speakerId;

          if (silenceTimeoutId) {
            clearTimeout(silenceTimeoutId);
          }

          silenceTimeoutId = setTimeout(() => {
            const timeSinceLastWord = Date.now() - lastWordTime;
            console.log(`‚è±Ô∏è  Silencio detectado (${timeSinceLastWord}ms desde √∫ltima palabra)`);
            processCompleteUtterance();
          }, SILENCE_TIMEOUT);

          console.log(`   Total acumulado: ${currentUtterance.length} palabras`);
        }
      } else if (data.event === 'transcript.partial_data') {
        console.log('   ‚è≠Ô∏è  Ignorando partial_data');
      }
      
    } catch (e) {
      console.error('‚ùå Error procesando mensaje:', e.message);
    }
  });

  ws.on('close', async function close(code, reason) {
    console.log(`\n‚ùå Conexi√≥n cerrada desde: ${clientIp}`);
    console.log(`   C√≥digo: ${code}, Raz√≥n: ${reason || 'No especificada'}`);
    
    if (currentUtterance.length > 0) {
      await processCompleteUtterance();
    }
    
    if (silenceTimeoutId) {
      clearTimeout(silenceTimeoutId);
    }
    
    if (conversationTimeoutId) {
      clearTimeout(conversationTimeoutId);
    }
  });

  ws.on('error', function error(err) {
    console.error('‚ùå Error en WebSocket:', err.message);
  });

  const pingInterval = setInterval(() => {
    if (ws.readyState === WebSocket.OPEN) {
      ws.ping();
    }
  }, 30000);

  ws.on('close', () => {
    clearInterval(pingInterval);
  });
});

process.on('uncaughtException', (error) => {
  console.error('‚ùå Error no capturado:', error);
});

process.on('unhandledRejection', (reason) => {
  console.error('‚ùå Promesa rechazada:', reason);
});

console.log('\nüì° Esperando conexiones de Recall.ai...\n');
